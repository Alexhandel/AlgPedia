ABOUT
In computer science, the Hopcroft–Karp algorithm is an algorithm that takes as input a bipartite graph and produces as output a maximum cardinality matching – a set of as many edges as possible with the property that no two edges share an endpoint. It runs in 



O
(

|

E

|




|

V

|



)


{\displaystyle O(|E|{\sqrt {|V|}})}

 time in the worst case, where 



E


{\displaystyle E}

 is set of edges in the graph, and 



V


{\displaystyle V}

 is set of vertices of the graph. In the case of dense graphs the time bound becomes 



O
(

|

V


|


2.5


)


{\displaystyle O(|V|^{2.5})}

, and for random graphs it runs in near-linear time.
FULL TEXT
In computer science, the Hopcroft–Karp algorithm is an algorithm that takes as input a bipartite graph and produces as output a maximum cardinality matching – a set of as many edges as possible with the property that no two edges share an endpoint. It runs in 



O
(

|

E

|




|

V

|



)


{\displaystyle O(|E|{\sqrt {|V|}})}

 time in the worst case, where 



E


{\displaystyle E}

 is set of edges in the graph, and 



V


{\displaystyle V}

 is set of vertices of the graph. In the case of dense graphs the time bound becomes 



O
(

|

V


|


2.5


)


{\displaystyle O(|V|^{2.5})}

, and for random graphs it runs in near-linear time.
The algorithm was found by John Hopcroft and Richard Karp (1973). As in previous methods for matching such as the Hungarian algorithm and the work of Edmonds (1965), the Hopcroft–Karp algorithm repeatedly increases the size of a partial matching by finding augmenting paths: sequences of edges that alternate between being in and out of the matching, such that swapping which edges of the path are in and which are out of the matching produces a larger matching. However, instead of finding just a single augmenting path per iteration, the algorithm finds a maximal set of shortest augmenting paths. As a result, only 



O
(



|

V

|



)


{\displaystyle O({\sqrt {|V|}})}

 iterations are needed. The same principle has also been used to develop more complicated algorithms for non-bipartite matching with the same asymptotic running time as the Hopcroft–Karp algorithm.


A vertex that is not the endpoint of an edge in some partial matching 



M


{\displaystyle M}

 is called a free vertex. The basic concept that the algorithm relies on is that of an augmenting path, a path that starts at a free vertex, ends at a free vertex, and alternates between unmatched and matched edges within the path. It follows from this definition that, except for the endpoints, all other vertices (if any) in augmenting path must be non-free vertices. An augmenting path could consist of only two vertices (both free) and single unmatched edge between them.
If 



M


{\displaystyle M}

 is a matching, and 



P


{\displaystyle P}

 is an augmenting path relative to 



M


{\displaystyle M}

, then the symmetric difference of the two sets of edges, 



M
⊕
P


{\displaystyle M\oplus P}

, would form a matching with size 




|

M

|

+
1


{\displaystyle |M|+1}

. Thus, by finding augmenting paths, an algorithm may increase the size of the matching.
Conversely, suppose that a matching 



M


{\displaystyle M}

 is not optimal, and let 



P


{\displaystyle P}

 be the symmetric difference 



M
⊕

M

∗




{\displaystyle M\oplus M^{*}}

 where 




M

∗




{\displaystyle M^{*}}

 is an optimal matching. Because 



M


{\displaystyle M}

 and 




M

∗




{\displaystyle M^{*}}

 are both matchings, every vertex has degree at most 2 in 



P


{\displaystyle P}

. So 



P


{\displaystyle P}

 must form a collection of disjoint augmenting paths and cycles or paths in which matched and unmatched edges are of equal number; the difference in size between 



M


{\displaystyle M}

 and 




M

∗




{\displaystyle M^{*}}

 is the number of augmenting paths in 



P


{\displaystyle P}

. Thus, whenever there exists a matching 




M

∗




{\displaystyle M^{*}}

 larger than the current matching 



M


{\displaystyle M}

, there must also exist an augmenting path. If no augmenting path can be found, an algorithm may safely terminate, since in this case 



M


{\displaystyle M}

 must be optimal.
An augmenting path in a matching problem is closely related to the augmenting paths arising in maximum flow problems, paths along which one may increase the amount of flow between the terminals of the flow. It is possible to transform the bipartite matching problem into a maximum flow instance, such that the alternating paths of the matching problem become augmenting paths of the flow problem.[1] In fact, a generalization of the technique used in Hopcroft–Karp algorithm to arbitrary flow networks is known as Dinic's algorithm.
The algorithm may be expressed in the following pseudocode.
In more detail, let 



U


{\displaystyle U}

 and 



V


{\displaystyle V}

 be the two sets in the bipartition of 



G


{\displaystyle G}

, and let the matching from 



U


{\displaystyle U}

 to 



V


{\displaystyle V}

 at any time be represented as the set 



M


{\displaystyle M}

. The algorithm is run in phases. Each phase consists of the following steps.
The algorithm terminates when no more augmenting paths are found in the breadth first search part of one of the phases.
Each phase consists of a single breadth first search and a single depth first search. Thus, a single phase may be implemented in linear time. Therefore, the first 






|

V

|





{\displaystyle {\sqrt {|V|}}}

 phases, in a graph with 




|

V

|



{\displaystyle |V|}

 vertices and 




|

E

|



{\displaystyle |E|}

 edges, take time 



O
(

|

E

|




|

V

|



)


{\displaystyle O(|E|{\sqrt {|V|}})}

.
It can be shown that each phase increases the length of the shortest augmenting path by at least one: the phase finds a maximal set of augmenting paths of the given length, so any remaining augmenting path must be longer. Therefore, once the initial 






|

V

|





{\displaystyle {\sqrt {|V|}}}

 phases of the algorithm are complete, the shortest remaining augmenting path has at least 






|

V

|





{\displaystyle {\sqrt {|V|}}}

 edges in it. However, the symmetric difference of the eventual optimal matching and of the partial matching M found by the initial phases forms a collection of vertex-disjoint augmenting paths and alternating cycles. If each of the paths in this collection has length at least 






|

V

|





{\displaystyle {\sqrt {|V|}}}

, there can be at most 






|

V

|





{\displaystyle {\sqrt {|V|}}}

 paths in the collection, and the size of the optimal matching can differ from the size of 



M


{\displaystyle M}

 by at most 






|

V

|





{\displaystyle {\sqrt {|V|}}}

 edges. Since each phase of the algorithm increases the size of the matching by at least one, there can be at most 






|

V

|





{\displaystyle {\sqrt {|V|}}}

 additional phases before the algorithm terminates.
Since the algorithm performs a total of at most 



2



|

V

|





{\displaystyle 2{\sqrt {|V|}}}

 phases, it takes a total time of 



O
(

|

E

|




|

V

|



)


{\displaystyle O(|E|{\sqrt {|V|}})}

 in the worst case.
In many instances, however, the time taken by the algorithm may be even faster than this worst case analysis indicates. For instance, in the average case for sparse bipartite random graphs, Bast et al. (2006) (improving a previous result of Motwani 1994) showed that with high probability all non-optimal matchings have augmenting paths of logarithmic length. As a consequence, for these graphs, the Hopcroft–Karp algorithm takes 



O
(
log
⁡

|

V

|

)


{\displaystyle O(\log |V|)}

 phases and 



O
(

|

E

|

log
⁡

|

V

|

)


{\displaystyle O(|E|\log |V|)}

 total time.
For sparse graphs, the Hopcroft–Karp algorithm continues to have the best known worst-case performance, but for dense graphs a more recent algorithm by Alt et al. (1991) achieves a slightly better time bound, 



O

(

n

1.5





m

log
⁡
n




)



{\displaystyle O\left(n^{1.5}{\sqrt {\frac {m}{\log n}}}\right)}

. Their algorithm is based on using a push-relabel maximum flow algorithm and then, when the matching created by this algorithm becomes close to optimum, switching to the Hopcroft–Karp method.
Several authors have performed experimental comparisons of bipartite matching algorithms. Their results in general tend to show that the Hopcroft–Karp method is not as good in practice as it is in theory: it is outperformed both by simpler breadth-first and depth-first strategies for finding augmenting paths, and by push-relabel techniques.[2]
The same idea of finding a maximal set of shortest augmenting paths works also for finding maximum cardinality matchings in non-bipartite graphs, and for the same reasons the algorithms based on this idea take 



O
(



|

V

|



)


{\displaystyle O({\sqrt {|V|}})}

 phases. However, for non-bipartite graphs, the task of finding the augmenting paths within each phase is more difficult. Building on the work of several slower predecessors, Micali & Vazirani (1980) showed how to implement a phase in linear time, resulting in a non-bipartite matching algorithm with the same time bound as the Hopcroft–Karp algorithm for bipartite graphs. The Micali–Vazirani technique is complex, and its authors did not provide full proofs of their results; subsequently, a "clear exposition" was published by Peterson & Loui (1988) and alternative methods were described by other authors.[3] In 2012, Vazirani offered a new simplified proof of the Micali-Vazirani algorithm.[4]
Let our graph have two partitions U, V. The key idea is to add two dummy vertices on each side of the graph: uDummy connecting to it to all unmatched vertices in U and vDummy connecting to all unmatched vertices in V. Now if we run BFS from uDummy to vDummy then we can get shortest path between an unmatched vertex in U to unmatched vertex in V. Due to bipartite nature of the graph, this path would zig zag from U to V. However we need to make sure that when going from V to U, we always select matched edge. If there is no matched edge then we end at vDummy. If we make sure of this criteria during BFS then the generated path would meet the criteria for being an augmented shortest path.
Once we have found the augmented shortest path, we want to make sure we ignore any other paths that are longer than this shortest paths. BFS algorithm marks nodes in path with distance with source being 0. Thus, after doing BFS, we can start at each unmatched vertex in U, follow the path by following nodes with distance that increments by 1. When we finally arrive at the destination vDummy, if its distance is 1 more than last node in V then we know that the path we followed is (one of the possibly many) shortest path. In that case we can go ahead and update the pairing for vertices on path in U and V. Note that each vertex in V on path, except for the last one, is non-free vertex. So updating pairing for these vertices in V to different vertices in U is equivalent to removing previously matched edge and adding new unmatched edge in matching. This is same as doing the symmetric difference (i.e. remove edges common to previous matching and add non-common edges in augmented path in new matching).
How do we make sure augmented paths are vertex disjoint? It is already guaranteed: After doing the symmetric difference for a path, none of its vertices could be considered again just because the Dist[ Pair_V[v] ] will not be equal to Dist[u] + 1 (It would be exactly Dist[u]).
So what is the mission of these two lines in pseudocode?:
When we were not able to find any shortest augmented path from a vertex, DFS returns false. In this case it would be good to mark these vertices to not to visit them again. This marking is simply done by setting Dist[u] to infinity.
Finally, we actually don't need uDummy because it's there just to put all unmatched vertices of U in queue when BFS starts. That we can do as just as initialization. The vDummy can be appended in U for convenience in many implementations and initialize default pairing for all V to point to vDummy. That way, if final vertex in V doesn't have any matching vertex in U then we finally end at vDummy which is the end of our augmented path. In above pseudocode vDummy is denoted as Nil.