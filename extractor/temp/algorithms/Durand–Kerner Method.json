{
    "about": "In numerical analysis, the Durand\u2013Kerner method, discovered by Karl Weierstrass in 1891 and rediscovered independently by Durand in 1960 and Kerner in 1966, is a root-finding algorithm for solving polynomial equations.[1] In other words, the method can be used to solve numerically the equation", 
    "name": "Durand\u2013Kerner Method", 
    "classification": "Root-Finding Algorithms", 
    "full_text": "In numerical analysis, the Durand\u2013Kerner method, discovered by Karl Weierstrass in 1891 and rediscovered independently by Durand in 1960 and Kerner in 1966, is a root-finding algorithm for solving polynomial equations.[1] In other words, the method can be used to solve numerically the equation\nwhere \u0192 is a given polynomial, which can be taken to be scaled so that the leading coefficient is\u00a01.\n\n\nThe explanation is for equations of degree four. It is easily generalized to other degrees.\nLet the polynomial \u0192 be defined by\nfor all x.\nThe known numbers a, b, c, d are the coefficients.\nLet the (complex) numbers P,Q,R,S be the roots of this polynomial \u0192.\nThen\nfor all x. One can isolate the value P from this equation,\nSo if used as a fixed point iteration\nit is strongly stable in that every initial point x0 \u2260 Q,R,S delivers after one iteration the root P=x1.\nFurthermore, if one replaces the zeros Q, R and S by approximations q \u2248 Q, r \u2248 R, s \u2248 S, such that q,r,s are not equal to P, then P is still a fixed point of the perturbed fixed point iteration\nsince\nNote that the denominator is still different from zero. This fixed point iteration is a contraction mapping for x around P.\nThe clue to the method now is to combine the fixed point iteration for P with similar iterations for Q,R,S into a simultaneous iteration for all roots.\nInitialize p, q, r, s:\nThere is nothing special about choosing 0.4\u00a0+\u00a00.9\u00a0i except that it is neither a real number nor a root of unity.\nMake the substitutions for n = 1,2,3,\u00b7\u00b7\u00b7\nRe-iterate until the numbers p, q, r, s stop essentially changing in relative to the desired precision. Then they have the values P, Q, R, S in some order and in the chosen precision. So the problem is solved.\nNote that you must use complex number arithmetic, and that the roots are found simultaneously rather than one at a time.\nThis iteration procedure, like the Gauss\u2013Seidel method for linear equations, computes one number at a time based on the already computed numbers. A variant of this procedure, like the Jacobi method, computes a vector of root approximations at a time. Both variant are effective root-finding algorithms.\nOne could also choose the initial values for p,q,r,s by some other procedure, even randomly, but in a way that\nand that\nwhich may increasingly become a concern as the degree of the polynomial increases.\nIf the coefficients are real and the polynomial has odd degree, then it must have at least one real root. To find this, use a real value of p0 as the initial guess and make q0 and r0, etc, complex conjugate pairs. Then the iteration will preserve these properties; that is, pn will always be real, and qn and rn, etc, will always be conjugate. In this way, the pn will converge to a real root P. Alternatively, make all of the initial guesses real; they will remain so.\nThis example is from the reference 1992. The equation solved is x3 \u2212 3x2 + 3x \u2212 5 = 0. The first 4 iterations move p, q, r seemingly chaotically, but then the roots are located to 1 decimal. After iteration number 5 we have 4 correct decimals, and the subsequent iteration number 6 confirms that the computed roots are fixed. This general behaviour is characteristic for the method.\nNote that the equation has one real root and one pair of complex conjugate roots, and that the sum of the roots is\u00a03.\nFor every n-tuple of complex numbers, there is exactly one monic polynomial of degree n that has them as its zeros (keeping multiplicities). This polynomial is given by multiplying all the corresponding linear factors, that is\nThis polynomial has coefficients that depend on the prescribed zeros,\nThose coefficients are, up to a sign, the elementary symmetric polynomials \n\n\n\n\n\u03b1\n\n1\n\n\n(\n\n\n\nz\n\u2192\n\n\n\n)\n,\n\u2026\n,\n\n\u03b1\n\nn\n\n\n(\n\n\n\nz\n\u2192\n\n\n\n)\n\n\n{\\displaystyle \\alpha _{1}({\\vec {z}}),\\dots ,\\alpha _{n}({\\vec {z}})}\n\n of degrees 1,...,n.\nTo find all the roots of a given polynomial \n\n\n\nf\n(\nX\n)\n=\n\nX\n\nn\n\n\n+\n\nc\n\nn\n\u2212\n1\n\n\n\nX\n\nn\n\u2212\n1\n\n\n+\n\u22ef\n+\n\nc\n\n0\n\n\n\n\n{\\displaystyle f(X)=X^{n}+c_{n-1}X^{n-1}+\\cdots +c_{0}}\n\n with coefficient vector \n\n\n\n(\n\nc\n\nn\n\u2212\n1\n\n\n,\n\u2026\n,\n\nc\n\n0\n\n\n)\n\n\n{\\displaystyle (c_{n-1},\\dots ,c_{0})}\n\n simultaneously is now the same as to find a solution vector to the system\nThe Durand\u2013Kerner method is obtained as the multidimensional Newton's method applied to this system. It is algebraically more comfortable to treat those identities of coefficients as the identity of the corresponding polynomials, \n\n\n\n\ng\n\n\n\nz\n\u2192\n\n\n\n\n(\nX\n)\n=\nf\n(\nX\n)\n\n\n{\\displaystyle g_{\\vec {z}}(X)=f(X)}\n\n. In the Newton's method one looks, given some initial vector \n\n\n\n\n\n\nz\n\u2192\n\n\n\n\n\n{\\displaystyle {\\vec {z}}}\n\n, for an increment vector \n\n\n\n\n\n\nw\n\u2192\n\n\n\n\n\n{\\displaystyle {\\vec {w}}}\n\n such that \n\n\n\n\ng\n\n\n\n\nz\n\u2192\n\n\n\n+\n\n\n\nw\n\u2192\n\n\n\n\n\n(\nX\n)\n=\nf\n(\nX\n)\n\n\n{\\displaystyle g_{{\\vec {z}}+{\\vec {w}}}(X)=f(X)}\n\n is satisfied up to second and higher order terms in the increment. For this one solves the identity\nIf the numbers \n\n\n\n\nz\n\n1\n\n\n,\n\u2026\n,\n\nz\n\nn\n\n\n\n\n{\\displaystyle z_{1},\\dots ,z_{n}}\n\n are pairwise different, then the polynomials in the terms of the right hand side form a basis of the n-dimensional space \n\n\n\n\nC\n\n[\nX\n\n]\n\nn\n\u2212\n1\n\n\n\n\n{\\displaystyle \\mathbb {C} [X]_{n-1}}\n\n of polynomials with maximal degree n\u00a0\u2212\u00a01. Thus a solution \n\n\n\n\n\n\nw\n\u2192\n\n\n\n\n\n{\\displaystyle {\\vec {w}}}\n\n to the increment equation exists in this case. The coordinates of the increment \n\n\n\n\n\n\nw\n\u2192\n\n\n\n\n\n{\\displaystyle {\\vec {w}}}\n\n are simply obtained by evaluating the increment equation\nat the points \n\n\n\nX\n=\n\nz\n\nk\n\n\n\n\n{\\displaystyle X=z_{k}}\n\n, which results in\nIn the quotient ring (algebra) of residue classes modulo \u0192(X), the multiplication by X defines an endomorphism that has the zeros of \u0192(X) as eigenvalues with the corresponding multiplicities. Choosing a basis, the multiplication operator is represented by its coefficient matrix A, the companion matrix of \u0192(X) for this basis.\nSince every polynomial can be reduced modulo \u0192(X) to a polynomial of degree n\u00a0\u2212\u00a01 or lower, the space of residue classes can be identified with the space of polynomials of degree bounded by n\u00a0\u2212\u00a01. A problem specific basis can be taken from Lagrange interpolation as the set of n polynomials\nwhere \n\n\n\n\nz\n\n1\n\n\n,\n\u2026\n,\n\nz\n\nn\n\n\n\u2208\n\nC\n\n\n\n{\\displaystyle z_{1},\\dots ,z_{n}\\in \\mathbb {C} }\n\n are pairwise different complex numbers. Note that the kernel functions for the Lagrange interpolation are \n\n\n\n\nL\n\nk\n\n\n(\nX\n)\n=\n\n\n\n\nb\n\nk\n\n\n(\nX\n)\n\n\n\nb\n\nk\n\n\n(\n\nz\n\nk\n\n\n)\n\n\n\n\n\n{\\displaystyle L_{k}(X)={\\frac {b_{k}(X)}{b_{k}(z_{k})}}}\n\n.\nFor the multiplication operator applied to the basis polynomials one obtains from the Lagrange interpolation\nwhere \n\n\n\n\nw\n\nj\n\n\n=\n\u2212\n\n\n\nf\n(\n\nz\n\nj\n\n\n)\n\n\n\nb\n\nj\n\n\n(\n\nz\n\nj\n\n\n)\n\n\n\n\n\n{\\displaystyle w_{j}=-{\\frac {f(z_{j})}{b_{j}(z_{j})}}}\n\n are again the Weierstrass updates.\nThe companion matrix of \u0192(X) is therefore\nFrom the transposed matrix case of the Gershgorin circle theorem it follows that all eigenvalues of A, that is, all roots of \u0192(X), are contained in the union of the disks \n\n\n\nD\n(\n\na\n\nk\n,\nk\n\n\n,\n\nr\n\nk\n\n\n)\n\n\n{\\displaystyle D(a_{k,k},r_{k})}\n\n with a radius \n\n\n\n\nr\n\nk\n\n\n=\n\n\u2211\n\nj\n\u2260\nk\n\n\n\n\n|\n\n\n\na\n\nj\n,\nk\n\n\n\n\n|\n\n\n\n\n{\\displaystyle r_{k}=\\sum _{j\\neq k}{\\big |}a_{j,k}{\\big |}}\n\n.\nHere one has \n\n\n\n\na\n\nk\n,\nk\n\n\n=\n\nz\n\nk\n\n\n+\n\nw\n\nk\n\n\n\n\n{\\displaystyle a_{k,k}=z_{k}+w_{k}}\n\n, so the centers are the next iterates of the Weierstrass iteration, and radii \n\n\n\n\nr\n\nk\n\n\n=\n(\nn\n\u2212\n1\n)\n\n|\n\nw\n\nk\n\n\n|\n\n\n\n{\\displaystyle r_{k}=(n-1)\\left|w_{k}\\right|}\n\n that are multiples of the Weierstrass updates. If the roots of \u0192(X) are all well isolated (relative to the computational precision) and the points \n\n\n\n\nz\n\n1\n\n\n,\n\u2026\n,\n\nz\n\nn\n\n\n\u2208\n\nC\n\n\n\n{\\displaystyle z_{1},\\dots ,z_{n}\\in \\mathbb {C} }\n\n are sufficidently close approximations to these roots, then all the disks will become disjoint, so each one contains exactly one zero. The midpoints of the circles will be better approximations of the zeros.\nEvery conjugate matrix \n\n\n\nT\nA\n\nT\n\n\u2212\n1\n\n\n\n\n{\\displaystyle TAT^{-1}}\n\n of A is as well a companion matrix of \u0192(X). Choosing T as diagonal matrix leaves the structure of A invariant. The root close to \n\n\n\n\nz\n\nk\n\n\n\n\n{\\displaystyle z_{k}}\n\n is contained in any isolated circle with center \n\n\n\n\nz\n\nk\n\n\n\n\n{\\displaystyle z_{k}}\n\n regardless of T. Choosing the optimal diagonal matrix T for every index results in better estimates (see ref. Petkovic et al. 1995).\nThe connection between the Taylor series expansion and Newton's method suggests that the distance from \n\n\n\n\nz\n\nk\n\n\n+\n\nw\n\nk\n\n\n\n\n{\\displaystyle z_{k}+w_{k}}\n\n to the corresponding root is of the order \n\n\n\nO\n(\n\n|\n\n\nw\n\nk\n\n\n\n\n|\n\n\n2\n\n\n)\n\n\n{\\displaystyle O(|w_{k}|^{2})}\n\n, if the root is well isolated from nearby roots and the approximation is sufficiently close to the root. So after the approximation is close, Newton's method converges quadratically; that is: the error is squared with every step (which will greatly reduce the error once it is less than 1). In the case of the Durand\u2013Kerner method, convergence is quadratic if the vector \n\n\n\n\n\n\nz\n\u2192\n\n\n\n=\n(\n\nz\n\n1\n\n\n,\n\u2026\n,\n\nz\n\nn\n\n\n)\n\n\n{\\displaystyle {\\vec {z}}=(z_{1},\\dots ,z_{n})}\n\n is close to some permutation of the vector of the roots of \u0192.\nFor the conclusion of linear convergence there is a more specific result (see ref. Petkovic et al. 1995). If the initial vector \n\n\n\n\n\n\nz\n\u2192\n\n\n\n\n\n{\\displaystyle {\\vec {z}}}\n\n and its vector of Weierstrass updates \n\n\n\n\n\n\nw\n\u2192\n\n\n\n=\n(\n\nw\n\n1\n\n\n,\n\u2026\n,\n\nw\n\nn\n\n\n)\n\n\n{\\displaystyle {\\vec {w}}=(w_{1},\\dots ,w_{n})}\n\n satisfies the inequality\nthen this inequality also holds for all iterates, all inclusion disks \n\n\n\n\nD\n\n(\n\nz\n\nk\n\n\n+\n\nw\n\nk\n\n\n,\n(\nn\n\u2212\n1\n)\n\n|\n\n\nw\n\nk\n\n\n\n|\n\n)\n\n\n\n\n{\\displaystyle \\textstyle D\\left(z_{k}+w_{k},(n-1)|w_{k}|\\right)}\n\n are disjoint and linear convergence with a contraction factor of 1/2 holds. Further, the inclusion disks can in this case be chosen as\neach containing exactly one zero of \u0192.", 
    "dbpedia_url": "http://dbpedia.org/resource/Durand\u2013Kerner_method", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Durand\u2013Kerner_method\n"
}