{
    "about": "Nelder\u2013Mead simplex search over the Rosenbrock banana function (above) and Himmelblau's function (below)", 
    "name": "Nelder\u2013Mead Method", 
    "classification": "Optimization Algorithms And Methods", 
    "full_text": "Nelder\u2013Mead simplex search over the Rosenbrock banana function (above) and Himmelblau's function (below)\nThe Nelder\u2013Mead method or downhill simplex method or amoeba method is a commonly applied numerical method used to find the minimum or maximum of an objective function in a multidimensional space. It is applied to nonlinear optimization problems for which derivatives may not be known. However, the Nelder\u2013Mead technique is a heuristic search method that can converge to non-stationary points[1] on problems that can be solved by alternative methods.[2]\nThe Nelder\u2013Mead technique was proposed by John Nelder & Roger Mead (1965).[3]\n\n\nThe method uses the concept of a simplex, which is a special polytope of n\u00a0+\u00a01 vertices in n dimensions. Examples of simplices include a line segment on a line, a triangle on a plane, a tetrahedron in three-dimensional space and so forth.\nThe method approximates a local optimum of a problem with n variables when the objective function varies smoothly and is unimodal.\nFor example, a suspension bridge engineer has to choose how thick each strut, cable, and pier must be. These elements are interdependent, but it is not easy to visualize the impact of changing any specific element. Simulation of such complicated structures is often extremely computationally expensive to run, possibly taking upwards of hours per execution. An engineer may therefore prefer the Nelder\u2013Mead method as it requires fewer evaluations per iteration than other optimization methods.\nNelder\u2013Mead in n dimensions maintains a set of n+1 test points arranged as a simplex. It then extrapolates the behavior of the objective function measured at each test point, in order to find a new test point and to replace one of the old test points with the new one, and so the technique progresses. The simplest approach is to replace the worst point with a point reflected through the centroid of the remaining n points. If this point is better than the best current point, then we can try stretching exponentially out along this line. On the other hand, if this new point isn't much better than the previous value, then we are stepping across a valley, so we shrink the simplex towards a better point. An intuitive explanation of the algorithm is presented in [4]\nThe downhill simplex method now takes a series of steps, most steps just moving the point of the simplex where the function is largest (\u201chighest point\u201d) through the opposite face of the simplex to a lower point. These steps are called reflections, and they are constructed to conserve the volume of the simplex (and hence maintain its nondegeneracy). When it can do so, the method expands the simplex in one or another direction to take larger steps. When it reaches a \u201cvalley floor,\u201d the method contracts itself in the transverse direction and tries to ooze down the valley. If there is a situation where the simplex is trying to \u201cpass through the eye of a needle,\u201d it contracts itself in all directions, pulling itself in around its lowest (best) point.\nUnlike modern optimization methods, the Nelder\u2013Mead heuristic can converge to a non-stationary point unless the problem satisfies stronger conditions than are necessary for modern methods.[1] Modern improvements over the Nelder\u2013Mead heuristic have been known since 1979.[2]\nMany variations exist depending on the actual nature of the problem being solved. A common variant uses a constant-size, small simplex that roughly follows the gradient direction (which gives steepest descent). Visualize a small triangle on an elevation map flip-flopping its way down a valley to a local bottom. This method is also known as the Flexible Polyhedron Method. This, however, tends to perform poorly against the method described in this article(?) because it makes small, unnecessary steps in areas of little interest.\nWe are trying to minimize the function \n\n\n\nf\n(\n\nx\n\n)\n\n\n{\\displaystyle f(\\mathbf {x} )}\n\n, where \n\n\n\n\nx\n\n\u2208\n\n\n\nR\n\n\n\nn\n\n\n\n\n{\\displaystyle \\mathbf {x} \\in {\\mathbb {R}}^{n}}\n\n. Our current test points are \n\n\n\n\n\nx\n\n\n1\n\n\n,\n\u2026\n,\n\n\nx\n\n\nn\n+\n1\n\n\n\n\n{\\displaystyle \\mathbf {x} _{1},\\ldots ,\\mathbf {x} _{n+1}}\n\n.\n1. Order according to the values at the vertices:\n2. Calculate \n\n\n\n\n\nx\n\n\no\n\n\n\n\n{\\displaystyle \\mathbf {x} _{o}}\n\n, the centroid of all points except \n\n\n\n\n\nx\n\n\nn\n+\n1\n\n\n\n\n{\\displaystyle \\mathbf {x} _{n+1}}\n\n.\n3. Reflection\n4. Expansion\n5. Contraction\n6. Shrink\nNote: \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n, \n\n\n\n\u03b3\n\n\n{\\displaystyle \\gamma }\n\n, \n\n\n\n\u03c1\n\n\n{\\displaystyle \\rho }\n\n and \n\n\n\n\u03c3\n\n\n{\\displaystyle \\sigma }\n\n are respectively the reflection, expansion, contraction and shrink coefficients. Standard values are \n\n\n\n\u03b1\n=\n1\n\n\n{\\displaystyle \\alpha =1}\n\n, \n\n\n\n\u03b3\n=\n2\n\n\n{\\displaystyle \\gamma =2}\n\n, \n\n\n\n\u03c1\n=\n1\n\n/\n\n2\n\n\n{\\displaystyle \\rho =1/2}\n\n and \n\n\n\n\u03c3\n=\n1\n\n/\n\n2\n\n\n{\\displaystyle \\sigma =1/2}\n\n.\nFor the reflection, since \n\n\n\n\n\nx\n\n\nn\n+\n1\n\n\n\n\n{\\displaystyle \\mathbf {x} _{n+1}}\n\n is the vertex with the higher associated value among the vertices, we can expect to find a lower value at the reflection of \n\n\n\n\n\nx\n\n\nn\n+\n1\n\n\n\n\n{\\displaystyle \\mathbf {x} _{n+1}}\n\n in the opposite face formed by all vertices \n\n\n\n\n\nx\n\n\ni\n\n\n\n\n{\\displaystyle \\mathbf {x} _{i}}\n\n except \n\n\n\n\n\nx\n\n\nn\n+\n1\n\n\n\n\n{\\displaystyle \\mathbf {x} _{n+1}}\n\n.\nFor the expansion, if the reflection point \n\n\n\n\n\nx\n\n\nr\n\n\n\n\n{\\displaystyle \\mathbf {x} _{r}}\n\n is the new minimum along the vertices, we can expect to find interesting values along the direction from \n\n\n\n\n\nx\n\n\no\n\n\n\n\n{\\displaystyle \\mathbf {x} _{o}}\n\n to \n\n\n\n\n\nx\n\n\nr\n\n\n\n\n{\\displaystyle \\mathbf {x} _{r}}\n\n.\nConcerning the contraction, if \n\n\n\nf\n(\n\n\nx\n\n\nr\n\n\n)\n>\nf\n(\n\n\nx\n\n\nn\n\n\n)\n\n\n{\\displaystyle f(\\mathbf {x} _{r})>f(\\mathbf {x} _{n})}\n\n, we can expect that a better value will be inside the simplex formed by all the vertices \n\n\n\n\n\nx\n\n\ni\n\n\n\n\n{\\displaystyle \\mathbf {x} _{i}}\n\n.\nFinally, the shrink handles the rare case that contracting away from the largest point increases \n\n\n\nf\n\n\n{\\displaystyle f}\n\n, something that cannot happen sufficiently close to a non-singular minimum. In that case we contract towards the lowest point in the expectation of finding a simpler landscape.\nThe initial simplex is important. Indeed, a too small initial simplex can lead to a local search, consequently the NM can get more easily stuck. So this simplex should depend on the nature of the problem.", 
    "dbpedia_url": "http://dbpedia.org/resource/Nelder\u2013Mead_method", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Nelder\u2013Mead_method\n"
}